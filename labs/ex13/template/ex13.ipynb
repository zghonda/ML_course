{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoE7_FDHHkat"
   },
   "source": [
    "# Lab 13 – Adversarial Robustness\n",
    "\n",
    "Security and robustness of machine learning models have traditionally been often overlooked. It is usually quite easy for an adversary to create inputs (e.g. images) that look much like the originals to a human, but fool an ML model into thinking they are something else.\n",
    "\n",
    "![Illustration from Goodfellow et al. Adding imperceptible pixel-wise perturbations to an image can drastically alter a model's predictions.](https://miro.medium.com/max/573/1*Nj_toOwx_Hc5NLn97Jv-ww.png)\n",
    "\n",
    "In this lab, we will see that imperceptible perturbations to an image can cause drastically different model predictions. You will train two different image classifiers for hand-written digits: a logistic regression model and a neural net. For both, you will run the [Fast Gradient Sign Attack (FGSM)](https://arxiv.org/pdf/1412.6572.pdf), to try to fool them. Which one do you think will be more robust? Why?\n",
    "\n",
    "Making machine learning models provably robust against any attack is still an open area of research, but in the second part of this lab, we will explore if we can make the models robust against the attacks conducted in the first part.\n",
    "\n",
    "A few notes:\n",
    "- If you're interested to read more, note that research on adversarial examples is not limited to the image domain, check out `this <https://arxiv.org/pdf/1801.01944.pdf>` attack on speech-to-text models.\n",
    "- This lab is based on an official PyTorch tutorial on [Aversarial Example Generation](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WONGBZ44qRiU"
   },
   "source": [
    "## 1. Training a digit classifier\n",
    "-------------------------\n",
    "\n",
    "We will start by implementing a simple classifier for 28x28 black-and-white images of handwritten digits (the MNIST dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZB8fpDkDHkav"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaPQjvcxEzy2"
   },
   "source": [
    "### Implementing the `accuracy` function\n",
    "\n",
    "We will evaluate the quality of a classifier by its accuracy on the test set.\n",
    "\n",
    "__Exercise__ As a warm-up exercise, please complete the accuracy-function below and make sure that the tests pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ILOZIfcvwspy",
    "outputId": "4b45a281-21c9-486c-8d3b-2ed8c8b1fb7c"
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted_logits, reference):\n",
    "    \"\"\"\n",
    "    Compute the ratio of correctly predicted labels\n",
    "    \n",
    "    @param predicted_logits: float32 tensor of shape (batch size, num classes)\n",
    "    @param reference: int64 tensor of shape (batch_size) with the class number\n",
    "    \"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "def test_accuracy():\n",
    "    predictions = torch.tensor([[0.5, 1.0, 0.7], [-0.6, -0.3, 0]])\n",
    "    correct_labels = torch.tensor([0, 2])  # first is wrong, second is correct\n",
    "    assert accuracy(predictions, correct_labels).allclose(torch.tensor([0.5]))\n",
    "\n",
    "\n",
    "    predictions = torch.tensor([[0.5, 1.0, 0.7], [-0.6, -0.3, 0], [-1, 0, 1]])\n",
    "    correct_labels = torch.tensor([1, 1, 2])  # correct, wrong, correct\n",
    "    assert accuracy(predictions, correct_labels).allclose(torch.tensor([2/3]))\n",
    "\n",
    "    print(\"Tests passed\")\n",
    "  \n",
    "test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fM4xDA30GAri"
   },
   "source": [
    "### Logistic regression in PyTorch\n",
    "\n",
    "__Exercise__ Complete the PyTorch model below for logistic regression.\n",
    "Note that the model has 10 target classes, and therefore 10 outputs.\n",
    "Do not include the non-linear transformation that makes logistic regression different from linear least squares in the model. In PyTorch, this transformation is usually included in the loss function (`CrossEntropyLoss`). Don't forget to vectorize the input image before linear transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7uo0P7dtofd"
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_area = 28 * 28 # pixels\n",
    "        self.num_classes = 10\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO\n",
    "        # ***************************************************\n",
    "        self.linear_transform = # Fill HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        flattened_images = x.view(batch_size, self.image_area)\n",
    "        return self.linear_transform(flattened_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ijepok2GG7Q8"
   },
   "source": [
    "__Exercise__ Complete the training function below and train the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T06qNribrErv"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, dataset_train, dataset_test, optimizer, num_epochs):\n",
    "  \"\"\"\n",
    "  @param model: torch.nn.Module\n",
    "  @param criterion: torch.nn.modules.loss._Loss\n",
    "  @param dataset_train: torch.utils.data.DataLoader\n",
    "  @param dataset_test: torch.utils.data.DataLoader\n",
    "  @param optimizer: torch.optim.Optimizer\n",
    "  @param num_epochs: int\n",
    "  \"\"\"\n",
    "  print(\"Starting training\")\n",
    "  for epoch in range(num_epochs):\n",
    "    # Train an epoch\n",
    "    model.train()\n",
    "    for batch_x, batch_y in dataset_train:\n",
    "      batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "      # Evaluate the network (forward pass)\n",
    "      prediction = model(batch_x)\n",
    "      loss = criterion(prediction, batch_y)\n",
    "      \n",
    "      # Compute the gradient\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "\n",
    "      # Update the parameters of the model with a gradient step\n",
    "      optimizer.step()\n",
    "\n",
    "    # Test the quality on the test set\n",
    "    model.eval()\n",
    "    accuracies_test = []\n",
    "    for batch_x, batch_y in dataset_test:\n",
    "      batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "      # Evaluate the network (forward pass)\n",
    "      prediction = model(batch_x)\n",
    "      accuracies_test.append(accuracy(prediction, batch_y))\n",
    "\n",
    "    print(\"Epoch {} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies_test).item()/len(accuracies_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ycGiA_y2iafW",
    "outputId": "5687b56b-db8f-4e7b-f7d0-9fe5ea8a0e56"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 1000\n",
    "\n",
    "dataset_test = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=False, download=True, transform=torchvision.transforms.ToTensor()), \n",
    "  batch_size=100,\n",
    "  shuffle=True\n",
    ")\n",
    "dataset_train = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data', train=True, download=True, transform=torchvision.transforms.ToTensor()),\n",
    "  batch_size=batch_size,\n",
    "  shuffle=True\n",
    ")\n",
    "\n",
    "# If a GPU is available (should be on Colab, we will use it)\n",
    "if not torch.cuda.is_available():\n",
    "  raise Exception(\"Things will go much quicker if you enable a GPU in Colab under 'Runtime / Change Runtime Type'\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the logistic regression model with the Adam optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss() # this includes LogSoftmax which executes a logistic transformation\n",
    "model_logreg = LogisticRegressionModel().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_logreg.parameters(), lr=learning_rate)\n",
    "train(model_logreg, criterion, dataset_train, dataset_test, optimizer, num_epochs)\n",
    "\n",
    "# You should expect a test accuracy of around 91%.\n",
    "# Training should take around a minute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ehy22aHoKDzf"
   },
   "source": [
    "### A small convolutional network\n",
    "\n",
    "__Exercise__ Now, use the tools you built before to train this simple Convolutional Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Moh7XMmtJc7n"
   },
   "outputs": [],
   "source": [
    "class LeNetModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    \"\"\"From: LeCun et al., 1998. Gradient-Based Learning Applied to Document Recognition\"\"\"\n",
    "    super().__init__()\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    self.conv1 =  # XXX\n",
    "    self.conv2 = # XXX\n",
    "    self.conv2_drop = # XXX\n",
    "    self.fc1 = # XXX\n",
    "    self.fc2 = # XXX\n",
    "\n",
    "  def forward(self, x):\n",
    "    relu = torch.nn.functional.relu\n",
    "    max_pool2d = torch.nn.functional.max_pool2d\n",
    "\n",
    "    x = relu(max_pool2d(self.conv1(x), 2))\n",
    "    x = relu(max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = relu(self.fc1(x))\n",
    "    x = torch.nn.functional.dropout(x, training=self.training)\n",
    "    x = self.fc2(x)\n",
    "    return torch.nn.functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mjLWKuW_nshD",
    "outputId": "efe84847-6348-402d-ba52-1805e020c5c6"
   },
   "outputs": [],
   "source": [
    "model_lenet = LeNetModel().to(device)\n",
    "optimizer = torch.optim.Adam(model_lenet.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model_lenet, criterion, dataset_train, dataset_test, optimizer, num_epochs)\n",
    "\n",
    "# Expect roughly 97% accuracy on the test set.\n",
    "# Training should take around two minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5f-YxQVzyru"
   },
   "source": [
    "\n",
    "## 2. The Fast Gradient Sign Attack\n",
    "-------------------------\n",
    "\n",
    "One of the first and most popular adversarial attacks to date is\n",
    "referred to as the [Fast Gradient Sign Attack](https://arxiv.org/abs/1412.6572) and is described by Goodfellow et. al. in their paper 'Explaining and Harnessing Adversarial Examples'. The attack is remarkably powerful, and yet intuitive. It is designed to attack neural networks by leveraging the way they learn: *gradients*. The idea is simple. Rather than working to __minimize__ the loss by adjusting the __model parameters__ based on the backpropagated gradients, the attack optimizes the __input data__ to __maximize__ the loss. In other words, the attack computes the gradient of the loss w.r.t the input data, then adjusts the input data to maximize this loss.\n",
    "\n",
    "![Illustration from Goodfellow et al. Adding imperceptible pixel-wise perturbations to an image can drastically alter a model's predictions.](https://miro.medium.com/max/573/1*Nj_toOwx_Hc5NLn97Jv-ww.png)\n",
    "\n",
    "In the figure above, $\\mathbf{x}$ is the original input image\n",
    "correctly classified as a “panda”, $y$ is the ground truth label\n",
    "for $\\mathbf{x}$, $\\mathbf{\\theta}$ represents the model\n",
    "parameters, and $J(\\mathbf{\\theta}, \\mathbf{x}, y)$ is the loss\n",
    "that is used to train the network. The attack backpropagates the\n",
    "gradient back to the input data to calculate\n",
    "$\\nabla_{x} J(\\mathbf{\\theta}, \\mathbf{x}, y)$. Then, it adjusts\n",
    "the input data by a small step ($\\epsilon$ or $0.007$ in the\n",
    "picture) in the direction (i.e. $sign(\\nabla_{x} J(\\mathbf{\\theta}, \\mathbf{x}, y))$) that will\n",
    "maximize the loss. The resulting perturbed image, $x'$, is then *misclassified* by the target network as a “gibbon” when it is still\n",
    "clearly a “panda”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95T_alKBHka2"
   },
   "source": [
    "### Update rule\n",
    "\n",
    "__Exercise__ \n",
    "Let $\\mathbf{x}$ represent a network input (image) and let $J(\\theta, \\mathbf{x}, y)$ be the loss function of applying the network with parameters $\\theta$ to datapoint ($\\mathbf{x}$, $y$).\n",
    "Assuming that $J$ is linear in $\\mathbf{x}$ at the current $\\theta$, the perturbed image that achieves the highest loss while being not further than $\\epsilon$ away from $\\mathbf{x}$ in $L_\\infty$ norm is\n",
    "\n",
    "$$ \\text{perturbed }\\mathbf{x} = \\mathbf{x} - \\epsilon \\text{ sign}(\\nabla_xJ(\\theta,\\mathbf{x},y).$$\n",
    "\n",
    "Implement the update below (for a batch of images all at once). Makes sure pixel values stay in the image range $[0, 1]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xC8tUdYHka2"
   },
   "outputs": [],
   "source": [
    "def fgsm_update(image, data_grad, update_max_norm):\n",
    "    \"\"\"\n",
    "    Compute the FGSM update on an image (or a batch of images)\n",
    "\n",
    "    @param image: float32 tensor of shape (batch_size, rgb, height, width)\n",
    "    @param data_grad: float32 tensor of the same shape as `image`. Gradient of the loss with respect to `image`.\n",
    "    @param update_max_norm: float, the maximum permitted difference between `image` and the output of this function measured in L_inf norm.\n",
    "\n",
    "    @returns a perturbed version of `image` with the same shape\n",
    "    \"\"\"\n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO\n",
    "    # ***************************************************\n",
    "    \n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "\n",
    "    # Return the perturbed image\n",
    "    \n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuwR9SpqHka4"
   },
   "source": [
    "### Executing the attack\n",
    "\n",
    "__Exercise__ Complete the function below and perturb every digit in the test set such that the original models give as many incorrect predictions as possible. Use the `fgsm_update` function you created before.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q91gBNcVHka5"
   },
   "outputs": [],
   "source": [
    "def evaluate_attack(model, criterion, test_loader, update_max_norm):\n",
    "  \"\"\"\n",
    "  @param model: torch.nn.Module\n",
    "  @param criterion: torch.nn.modules.loss._Loss\n",
    "  @param test_loader: torch.util.data.DataLoader\n",
    "  @param update_max_norm: float indicating the maximum L_infinity norm allowed for the perturbations\n",
    "\n",
    "  @return (\n",
    "    accuracy of the model in the perturbed test set,\n",
    "    adversarial example images: list of 5 samples of a tuple (original prediction - float, prediction - float, example image - torch.tensor)\n",
    "  )\n",
    "  \"\"\"\n",
    "  accuracy_per_batch = []\n",
    "  adversarial_examples = []  # a small sample of 5 adversarial images\n",
    "\n",
    "  # Loop over all examples in test set in batches\n",
    "  for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Indicate that we want PyTorch to compute a gradient with respect to the\n",
    "    # input batch.\n",
    "    data.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(data)\n",
    "    original_predictions = output.argmax(1) # get the index of the max logit\n",
    "    original_accuracy = accuracy(output, target)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Zero all existing gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Perturb the batch with a gradient step (using the `fgsm_update`)\n",
    "    perturbed_data = fgsm_update(data, data.grad, update_max_norm)\n",
    "\n",
    "    # Re-classify the perturbed batch\n",
    "    output = model(perturbed_data)\n",
    "    adversarial_predictions = output.argmax(1)\n",
    "    adversarial_accuracy = accuracy(output, target)\n",
    "\n",
    "    accuracy_per_batch.append(adversarial_accuracy)\n",
    "\n",
    "    # Save some adversarial examples for visualization\n",
    "    if len(adversarial_examples) < 5:\n",
    "      adv_ex = perturbed_data[0, 0, :, :].detach().cpu().numpy()\n",
    "      adversarial_examples.append( (original_predictions[0].item(), adversarial_predictions[0].item(), adv_ex) )\n",
    "\n",
    "  average_accuracy = sum(accuracy_per_batch) / len(accuracy_per_batch)  # assuming all batches are the same size\n",
    "\n",
    "  print(\"Epsilon: {:.2f}\\tTest Accuracy = {:.3f}\".format(update_max_norm, average_accuracy))\n",
    "\n",
    "  return average_accuracy, adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvCW-Na-Hka7"
   },
   "source": [
    "### Accuracy vs perturbation magnitude\n",
    "\n",
    "Let's explore how the maximum allowed perturbation influences the model's test error.\n",
    "\n",
    "__Exercise__ At what maximum allowed perturbation ($\\epsilon$) does the model start to perform worse than random chance for 10-class classification with balanced classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "sBYC7mgEHka7",
    "outputId": "49c95f69-b12e-4c9e-c26e-26609eb5f3b1"
   },
   "outputs": [],
   "source": [
    "accuracies_logreg = []\n",
    "examples_logreg = []\n",
    "\n",
    "epsilons_logreg = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons_logreg:\n",
    "    acc, ex = evaluate_attack(model_logreg, criterion, dataset_test, eps)\n",
    "    accuracies_logreg.append(acc)\n",
    "    examples_logreg.append(ex)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_logreg, accuracies_logreg, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ibgZ1snR43nr"
   },
   "source": [
    "### Image quality\n",
    "\n",
    "The code below explores the visual relationship between perturbation and image quality. \n",
    "\n",
    "__Exercise__ Fill in the gaps. How many perturbed images would you get right yourself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "CyewFQpc333n",
    "outputId": "f6a24249-962d-455c-951b-ade8e3ada304"
   },
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "counter = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for epsilon, examples in zip(epsilons_logreg, examples_logreg):\n",
    "    for column_number, example in enumerate(examples):\n",
    "        counter += 1\n",
    "        original_prediction, adversarial_prediction, img = example\n",
    "        img = img.squeeze()\n",
    "\n",
    "        plt.subplot(len(epsilons_logreg), len(examples), counter)\n",
    "\n",
    "        plt.title(\"{} -> {}\".format(original_prediction, adversarial_prediction))\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "\n",
    "        # Clear the axes\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "\n",
    "        # Print y-labels in the first column\n",
    "        if column_number == 0:\n",
    "            plt.ylabel(\"Eps: {:.2f}\".format(epsilon), fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nG5RTfNr4KwA"
   },
   "source": [
    "### Logistic regression vs a ConvNet\n",
    "Now, let's run the same attack on the convolutional neural network you trained before. \n",
    "\n",
    "__Exercise__ Find out which model is more robust to this type of adversarial perturbations. Does the result match your expectations? Can you intuitively explain the result? Do the adversarial examples look similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "mDnQJIdT5nCA",
    "outputId": "c9bec12e-a4ec-4a9e-f0f6-1e424d273738"
   },
   "outputs": [],
   "source": [
    "accuracies_lenet = []\n",
    "examples_lenet = []\n",
    "\n",
    "epsilons_lenet = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons_lenet:\n",
    "    acc, ex = evaluate_attack(model_lenet, criterion, dataset_test, eps)\n",
    "    accuracies_lenet.append(acc)\n",
    "    examples_lenet.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "wq2fdeeh6bao",
    "outputId": "411028a0-19cc-4b22-e223-c4b41e8b6bfd"
   },
   "outputs": [],
   "source": [
    "# Comparing the models\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_logreg, accuracies_logreg, \"*-\", c='red', label='Logistic regression')\n",
    "plt.plot(epsilons_lenet, accuracies_lenet, \"*-\", c='blue', label='Convolutional network')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAoJXiXrziCO"
   },
   "source": [
    "## 3. Training a robust neural network model\n",
    "\n",
    "Training models that are robust against any adversarial input perturbations is an open research problem. Goodfellow et al., however, present an algorithm to defend against the Fast Gradient Sign Attack. \n",
    "\n",
    "The idea is simple: while training, adapt the training data to be a worst-case adversarial example by using the method developed before (details can be found in Section 5 of the [paper](https://arxiv.org/pdf/1412.6572.pdf)).\n",
    "\n",
    "__Exercise__: Complete the code for robust training below. Use your `fgsm_update` function to make sure every image that is presented to the network during training is 'optimally difficult' within, but not more different than 0.25 to the original in $L_\\infty$ distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "rJge1R3n2vKw",
    "outputId": "c56cc536-f728-4f36-ca8f-6a9e22ead0df"
   },
   "outputs": [],
   "source": [
    "robust_neural_net_model = LeNetModel().to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(robust_neural_net_model.parameters(), lr=1e-3)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Train an epoch\n",
    "    robust_neural_net_model.train()\n",
    "    for batch_x, batch_y in dataset_train:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        # Forward pass for adversarial perturbations\n",
    "        batch_x.requires_grad = True\n",
    "        output = robust_neural_net_model(batch_x)\n",
    "        original_predictions = output.argmax(1) # get the index of the max logit\n",
    "        original_accuracy = accuracy(output, batch_y)\n",
    "        loss = criterion(output, batch_y)\n",
    "        robust_neural_net_model.zero_grad()\n",
    "        loss.backward()\n",
    "        perturbed_data = fgsm_update(batch_x, batch_x.grad, 0.25)\n",
    "        \n",
    "        # Evaluate the network (forward pass)\n",
    "        prediction = robust_neural_net_model(perturbed_data)\n",
    "        loss = criterion(prediction, batch_y)\n",
    "        \n",
    "        # Compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters of the model with a gradient step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Test the quality on the test set\n",
    "    robust_neural_net_model.eval()\n",
    "    accuracies = []\n",
    "    for batch_x, batch_y in dataset_test:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        # Evaluate the network (forward pass)\n",
    "        prediction = robust_neural_net_model(batch_x)\n",
    "        accuracies.append(accuracy(prediction, batch_y))\n",
    "      \n",
    "    print(\"Epoch {:.2f} | Test accuracy: {:.5f}\".format(epoch, sum(accuracies).item()/len(accuracies)))\n",
    "\n",
    "\n",
    "  # training takes around two minutes\n",
    "  # you should expect an accuracy around 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "C119HVTIzScI",
    "outputId": "76cb2dc8-5fac-4d95-c34e-72ac16dcdabb"
   },
   "outputs": [],
   "source": [
    "accuracies_lenet_robust = []\n",
    "examples_lenet_robust = []\n",
    "\n",
    "epsilons_lenet_robust = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons_lenet_robust:\n",
    "    acc, ex = evaluate_attack(robust_neural_net_model, criterion, dataset_test, eps)\n",
    "    accuracies_lenet_robust.append(acc)\n",
    "    examples_lenet_robust.append(ex)\n",
    "\n",
    "# Comparing the models\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons_logreg, accuracies_logreg, \"*-\", c='red', label='Logistic regression')\n",
    "plt.plot(epsilons_lenet, accuracies_lenet, \"*-\", c='blue', label='Convolutional network')\n",
    "plt.plot(epsilons_lenet_robust, accuracies_lenet_robust, \"*-\", c='orange', label='Convolutional network (robust)')\n",
    "\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYy5aeo37Hw8"
   },
   "source": [
    "__Discussion__ Does adversarial training help? Is there a trade-off? Can you tune it to perform even better than with our default supplied parameters? How do you think the same defense would perform on the linear classification model?\n",
    "\n",
    "(optional) If you have heard about GANs, what are the similarities and difference between GAN training and this kind of adversarial training?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab 13 – Adversarial Robustness",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
